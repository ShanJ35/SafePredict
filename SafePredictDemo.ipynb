{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo of SafePredict with cod-rna dataset and Random Forest model\n",
    "\n",
    "In this demo, we will use online-learning to train a Random Forest model from scikit-learn on the popular cod-rna dataset. We will see how SafePredict can be used to bound the error rate of the predictions made by this model. Finally, we will introduce an artificial change in the data distribution in the middle of the dataset by randomly shuffling the class labels for half of the dataset to show how SafePredict is robust against such dramatic changes in the incoming data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing necessary libraries\n",
    "We import the safePredict method from the SafePredict library, the Random Forest model from scikit-learn, and other supporting libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SafePredict import safePredict\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the dataset\n",
    "We use the fetch_openml method provided by scikit-learn to get the cod-rna dataset and store it in two arrays 'X', and 'y' which hold the feature values and class labels respectively. \n",
    "\n",
    "Any other dataset can be passed to 'X' and 'y' here (for ex. by reading data from a .csv file), and a list of the datasets available directly from the fetch_openml function can be found here: https://www.openml.org/search?type=data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data...\n",
      "Received data!\n"
     ]
    }
   ],
   "source": [
    "X=[]\n",
    "y = []\n",
    "print(\"Getting data...\")\n",
    "X, y = fetch_openml('codrna', version=1, return_X_y=True)\n",
    "print(\"Received data!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "We arbitrarily modify the default class labels for the cod-rna dataset from '-1' and '1' to '0' and '1' respectively to show that feature engineering is compatible with SafePredict.\n",
    "\n",
    "This part is where you can do exploratory data analysis and feature engineering. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.astype(float)\n",
    "y = (y + 1)/2\n",
    "y = y.astype(int);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting dataset into train, validation, and test\n",
    "\n",
    "Here we use scikit-learn methods to split our dataset into distinct datasets that we will use for training, validation, and testing our models. Specifically, we will use 'X' and 'y' for training, 'holdout_X' and 'holdout_y' for testing, and 'rest_X' and 'rest_y' for validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_X, X, holdout_y, y = train_test_split(X, y, train_size=2500/len(y))\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "holdout_X = scaler.fit_transform(holdout_X)\n",
    "X = scaler.transform(X)\n",
    "X, rest_X, y, rest_y = train_test_split(X, y, train_size=10000/len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing an artificial change in the incoming data distribution\n",
    "\n",
    "Here, we simply shuffle the class labels after every change point to make the data meaningless (and thus as if its drawn from a different distribution!)\n",
    "\n",
    "numCP is the number of change points we want to introduce and that number can be any integer from 0 to T, with T being the size of the test dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = holdout_y.size\n",
    "numCP = 0\n",
    "if (numCP != 0):\n",
    "    for i in range(1, numCP + 1):\n",
    "        permuted_labels = np.random.permutation(np.arange(min(holdout_y[((i)*(T//(numCP+1))):((i+1)*(T//(numCP+1)))]),max(holdout_y[((i)*(T//(numCP+1))):((i+1)*(T//(numCP+1)))])+1))\n",
    "        for t in range((i)*(T//(numCP+1)),(i+1)*(T//(numCP+1))):\n",
    "            holdout_y[t] = permuted_labels[holdout_y[t]] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing SafePredict\n",
    "\n",
    "We will set only one parameter for SafePredict which is the target error rate. Info about all the parameters for SafePredict can be found in the README on GitHub: https://github.com/ShanJ35/SafePredict\n",
    "\n",
    "Epsilon is our target error rate, and here we set it an arbitrary value of 0.05, i.e., we want our error rate to be bounded at 5% of the total number of datapoints SafePredict sees. \n",
    "\n",
    "SafePredict uses a default Random Forest classifier as the default base predictor if not provided one by the user which works well for us since we will compare SafePredict using a Random Forest with a Random Forest model by itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 0.05\n",
    "sp =safePredict(target_error=epsilon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training SafePredict\n",
    "\n",
    "In order to simulate online-learning, we will pass one datapoint at a time to SafePredict, and retrain the base predictor every 100 datapoints. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = 100\n",
    "tl = tau\n",
    "horizon = X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 50.72it/s]\n",
      "  0%|          | 0/9900 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-d334f83b2726>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtau\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/Capstone/SKLearnContrib/SafePredict/_template.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Capstone/SKLearnContrib/SafePredict/_template.py\u001b[0m in \u001b[0;36m_predict\u001b[0;34m(self, X, y, random_state)\u001b[0m\n\u001b[1;32m    505\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_preds_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m             \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo_update\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "sp.fit(X[:tl].toarray(),y[:tl])\n",
    "for t in tqdm(range(tl, horizon)):\n",
    "    if t % tau == 0:\n",
    "        sp.estimator_.fit(X[:t], y[:t])\n",
    "    predictions.append(sp.predict(X[t].toarray(), y[t])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Error Rate\n",
    "\n",
    "We will now calculate the error rate for SafePredict, i.e., of the total number of datapoints that SafePredict received, how many it predicted incorrectly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = 0\n",
    "counter_sp = 0\n",
    "error_rates = []\n",
    "total_preds = len(predictions)\n",
    "print(\"Total predictions sp: \", total_preds)\n",
    "for i in tqdm(range(total_preds)):\n",
    "    if predictions[i] != (-1):\n",
    "        if predictions[i] != y[i+tl]:\n",
    "            errors = errors+1\n",
    "    counter_sp = counter_sp + 1\n",
    "    if counter_sp == 0:\n",
    "        error_rates.append(0)\n",
    "    else:\n",
    "        error_rates.append(errors/counter_sp)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeating experiment for Random Forest without SafePredict\n",
    "\n",
    "We will calculate the error rate when Random Forest is used without SafePredict in a similar online-learning setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()\n",
    "model.fit(X[:tl].toarray(), y[:tl])\n",
    "\n",
    "base_predictions = []\n",
    "for t in tqdm(range(tl, horizon)):\n",
    "    if t%tau == 0:\n",
    "        model.fit(X[:t].toarray(), y[:t])\n",
    "    base_predictions.append(model.predict(X[t].toarray())[0])\n",
    "\n",
    "base_err = 0\n",
    "counter = 0\n",
    "base_error_rates = []\n",
    "total_base_preds = len(base_predictions)\n",
    "for i in tqdm(range(total_base_preds)):\n",
    "    if base_predictions[i] != y[i+tl]:\n",
    "        base_err = base_err+1\n",
    "    counter = counter + 1\n",
    "    base_error_rates.append(base_err/counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting error rates\n",
    "\n",
    "We will now plot the error rates to show that the use of SafePredict bounds the error rate to the provided threshold. Especially after around 5000 samples, when the change point is introduced, we show that Random Forest by itself greatly increases in its error rate whereas SafePredict is robust against such changes and respects the error rate threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = []\n",
    "for i in range(total_preds):\n",
    "    threshold.append(epsilon)\n",
    "plt.plot(np.linspace(0,total_preds, total_preds), error_rates)\n",
    "plt.plot(np.linspace(0,total_preds, total_preds), base_error_rates)\n",
    "plt.plot(np.linspace(0,total_preds, total_preds), threshold)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
