{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo of SafePredict with cod-rna dataset and Random Forest model\n",
    "\n",
    "In this demo, we will use online-learning to train a Random Forest model from scikit-learn on the popular cod-rna dataset. We will see how SafePredict can be used to bound the error rate of the predictions made by this model. Finally, we will introduce an artificial change in the data distribution in the middle of the dataset by randomly shuffling the class labels for half of the dataset to show how SafePredict is robust against such dramatic changes in the incoming data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing necessary libraries\n",
    "We import the safePredict method from the SafePredict library, the Random Forest model from scikit-learn, and other supporting libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SafePredict import safePredict\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the dataset\n",
    "We use the fetch_openml method provided by scikit-learn to get the cod-rna dataset and store it in two arrays 'X', and 'y' which hold the feature values and class labels respectively. \n",
    "\n",
    "Any other dataset can be passed to 'X' and 'y' here (for ex. by reading data from a .csv file), and a list of the datasets available directly from the fetch_openml function can be found here: https://www.openml.org/search?type=data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data...\n",
      "Received data!\n"
     ]
    }
   ],
   "source": [
    "X=[]\n",
    "y = []\n",
    "print(\"Getting data...\")\n",
    "X, y = fetch_openml('codrna', version=1, return_X_y=True)\n",
    "print(\"Received data!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "We arbitrarily modify the default class labels for the cod-rna dataset from '-1' and '1' to '0' and '1' respectively to show that feature engineering is compatible with SafePredict.\n",
    "\n",
    "This part is where you can do exploratory data analysis and feature engineering. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.astype(float)\n",
    "y = (y + 1)/2\n",
    "y = y.astype(int);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting dataset into train, validation, and test\n",
    "\n",
    "Here we use scikit-learn methods to split our dataset into distinct datasets that we will use for training, validation, and testing our models. Specifically, we will use 'X' and 'y' for training, 'holdout_X' and 'holdout_y' for testing, and 'rest_X' and 'rest_y' for validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_X, X, holdout_y, y = train_test_split(X, y, train_size=2500/len(y))\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "holdout_X = scaler.fit_transform(holdout_X)\n",
    "X = scaler.transform(X)\n",
    "X, rest_X, y, rest_y = train_test_split(X, y, train_size=10000/len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing an artificial change in the incoming data distribution\n",
    "\n",
    "Here, we simply shuffle the class labels after every change point to make the data meaningless (and thus as if its drawn from a different distribution!)\n",
    "\n",
    "numCP is the number of change points we want to introduce and that number can be any integer from 0 to T, with T being the size of the training dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = holdout_y.size\n",
    "numCP = 0\n",
    "if (numCP != 0):\n",
    "    for i in range(1, numCP + 1):\n",
    "        permuted_labels = np.random.permutation(np.arange(min(holdout_y[((i)*(T//(numCP+1))):((i+1)*(T//(numCP+1)))]),max(holdout_y[((i)*(T//(numCP+1))):((i+1)*(T//(numCP+1)))])+1))\n",
    "        for t in range((i)*(T//(numCP+1)),(i+1)*(T//(numCP+1))):\n",
    "            holdout_y[t] = permuted_labels[holdout_y[t]] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing SafePredict\n",
    "\n",
    "We will set only one parameter for SafePredict which is the target error rate. Info about all the parameters for SafePredict can be found in the README on GitHub: https://github.com/ShanJ35/SafePredict\n",
    "\n",
    "Epsilon is our target error rate, and here we set it an arbitrary value of 0.05, i.e., we want our error rate to be bounded at 5% of the total number of datapoints SafePredict sees. \n",
    "\n",
    "SafePredict uses a default Random Forest classifier as the default base predictor if not provided one by the user which works well for us since we will compare SafePredict using a Random Forest with a Random Forest model by itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 0.05\n",
    "sp =safePredict(target_error=epsilon)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
